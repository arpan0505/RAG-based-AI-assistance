 Hi guys, my name is Nitish and you are welcome to my YouTube channel. In this video also we will continue our Langchain playlist. Now before starting the video, I would like to give you a quick recap of what we have covered in this playlist. I have put 15 videos in this playlist and we can divide the 15 videos into two parts. In the first part, we covered the fundamentals of Langchain. In which I told you about the components of Langchain and then we discussed those components one by one. Like the components of models, prompts, chains, etc. Then in the second part, we learned to make rag systems using Langchain. So we covered topics like document loaders, text splitters, vector stores, retrievers and finally we learned to make rag based systems. Now from here, we are going to start the third part of this playlist. Where we will learn how to build agents using Langchain. And in this part, I am going to add 3-4 videos. And today's video will be the first video for this segment. So in today's video, we are going to learn what tools are there in Langchain. So I will explain you in detail what the concept of tools is, how they fit in the agent's roadmap, and then I will also teach you how to create different types of tools in Langchain. On the whole, if you want to learn how to build agents using Langchain or Langraph, then in both the cases, you should have a good knowledge about tools. So in that sense, today's video is super important. So please make sure you watch this video end to end. Now, let's start the video. Now before moving forward in the video, I want to give you an overview. In this segment, we are going to cover exactly what topics we are going to cover. So first of all, we will cover tools, which is the topic of today's video. Here we will learn to work with different types of tools. We will also learn to make our own tools. After that, in the next video, we will cover a concept called tool calling. So what do you do in tool calling? You make the tool and connect your LLM with each other so that they can work together. So this is the topic of our next video. After that, we will cover the concept of agents. Where we will make agents using Langchain. And you will notice that in the process of making these agents, you will use LLMs, tools, and tool calling concepts. So basically, whatever you have studied so far, everything will be connected. And we are going to cover everything in agent. So in the topic of agent, I may need one or two videos. But the idea is that I want to explain in detail how agents are made using Langchain. So now that you have this high-level overview of what we are going to do in the next 2-4 videos, now let's start today's video. Let's focus on tools. So let's talk about tools. But to understand tools, we will first have to talk about LLMs. So LLMs, as you know, are very powerful natural language processing systems. If I ask you what is the biggest quality of LLMs, what is the biggest power of LLMs, then you will probably say two things. First, you will say that LLMs have reasoning capability. Which means that if you provide a question to LLMs, then LLM understands that question and breaks down how to answer that question. So basically, the LLM can think. This is the first core capability of an LLM. The second one is language generation. Once an LLM understands how to answer a given question, then after that, LLM generates an answer for you word by word. Which means, in a way, we can say that LLMs have the ability to speak. So in a nutshell, today's LLMs have two core capabilities. First, to think. Second, to speak. But that's it. Apart from this, LLMs have no other power. For example, if I ask an LLM, tell me, what is the best way to go to Bombay from Delhi? Then he will think and tell you the answer. He will say, flight is one option, train is one option, bus is another option. But if I ask him to book me on a train, then can LLM book you on a train? The answer is no. LLMs don't have the power to perform any tasks for you. So in a way, you can say that LLM is like a body, a human body, which has the capability to think and speak, but in that human body, it doesn't have hands and legs. Which means that it can't execute any tasks by itself. So there are a lot of tasks that today's computer systems can do, but LLMs can't do. For example, fetching live weather data. LLMs can't do that. Maths, doing it reliably. Now, basic addition and subtraction, LLM will perform it, but if you give it a complex math problem, there is a good chance that the answer that comes out is not reliable. Because, LLMs have not learned how to solve math, they have learned language generation. LLMs can't call external APIs. If you ask them to tweet on Twitter on my behalf, then LLMs can't do it. They can't run code. And they can't interact with databases. So in the real world, computer systems that can perform a lot of tasks, LLMs don't have that capability. So as I said, you can see LLMs as a human body, which has a brain, which can think, and can speak. But it can't do those things. It doesn't have hands and legs. So what are tools? Tools are a mechanism, with the help of which you can give your LLMs hands and legs. Meaning, you can create a tool to perform any given task, and you can connect that tool to your LLMs. As soon as you perform this connection, as soon as that task is given to your LLMs, then LLMs will execute that task with the help of that tool. Okay? Technically speaking, tools are nothing but functions. In which you have written the logic of executing a task. Now what you do is, you package this function in such a way, that this function can interact with LLMs. Okay? So for example, you made a function, which can perform a booking on the website of IRCTC, a train booking. Okay? And what did you do? You packaged this function in such a way, that LLMs can talk to this function. Okay? So as soon as I ask this LLM, to tell me trains from Delhi to Mumbai, then this LLM will tell me. Now as soon as I ask him to book me on this train, since this LLM now has the access to this function, then this LLM will also book you on this ticket with the help of this function. And that is the power of tools. That the more tools you add in LLMs, the more tasks your LLM can perform. Okay? So see, a very simple definition is written here. A tool is just a Python function, that is packaged in a way, the LLM can understand and call when needed. So LLM will think by itself, that when and what tool do I need? And then, according to him, he will call that tool, and provide it inputs. That tool will execute its work, and tell LLM back. LLM will tell you, the work is done. And this is the flow. Okay? So I hope you have understood roughly, what is the concept of tools. Tools is a way to provide LLM hands and legs, so that it can execute any kind of tasks. Now, if we discuss a little more about tools, then you get two types of tools in the langchain. One is built-in tools, and the second is custom tools. So, the team of the langchain has identified that there are many such tasks, which everyone needs. For example, Google search, or searching on the internet, or searching on Wikipedia, or running command line tools. So what they did is, they have already made built-in tools for these popular use cases in the langchain. Anyone can go and use these tools. And you don't need to write any code yourself. Okay? And the second is custom tools. It may be that you have a LLM plus tools system for your company, and you are making a tool system, and you get a use case that is only specific to your company. So what you can do there is, you can make custom tools for yourself. So going forward, I will teach you to work with both types of tools. I will also show you the built-in tools in the langchain, and I will also show you how you can make your own tools, and how you can connect them with LLM. Okay? Now, one big question, that the concept of tools, this agent, how is it related to the concept of agents? Because after all, we want to learn how to make agents. So, let's read the definition of agent here. See what is written here. An AI agent is an LLM powered system that can autonomously think, decide, and take actions using external tools or APIs to achieve a goal. Okay? So, agent is a system that has two capabilities. First, it can think, reason, and second, it can take action. Meaning, it can perform a task about what it has thought. Right? So, in a nutshell, agents have two capabilities. One is reasoning and decision making. Given a problem, they can think step by step, how to solve that problem. And once they think, they can actually perform action. Now, this reasoning and decision making part of the agent, this comes from LLM. Right? But, this action taking part, that I have to do this now, this you power using tools. So, in a nutshell, the marriage between LLMs and tools, we call that agent. And that is why, to build agents, the more important the concept of LLM is, the more important the concept of tools is. And that is why, I had told you in the beginning of the video, that if you have a Lang chain or a Lang graph, and you want to make agents with the help of Lang graph, then tools is a concept, which you should know well. Right? So, I really hope, the discussion we had in the last 5 minutes, around tools, you understood that. And now, we will try to understand at the level of how, how tools are made, and how they are used. So, first I will teach you, how to work with built-in tools. By the way, we just discussed, what are built-in tools. A built-in tool is a tool, that Lang chain already provides for you. It is pre-built, production ready, and requires minimal or no setup. Right? So, you don't have to write the function logic yourself, you just have to import and use it. The basic idea is, that there were some popular use cases, which the team of Lang chain thought, that everyone will need it. So, they have already made those tools, and put them in the library of Lang chain. Now, if you want to use those tools, then you don't need to write your own code. Simply import them, use them. Right? Here, I have written the names of some popular built-in tools, and have given their one line description. For example, there is one tool, DuckDuckGo Search. Right? With the help of this, you can search the web. DuckDuckGo is a very famous search engine, like Google. So, to search DuckDuckGo, a tool is already made in Lang chain. Second is, Wikipedia Query Run. On any topic, you can go and search on Wikipedia, and you can get a summarized version of it, and you can also search on Google. And then, you can also search on Google. So, this is the first step of this tool. Next is the Python REPL tool. With the help of this, you can run raw Python code. Right? Suppose, you want a factorial number. So, if you directly ask LLM, it is not necessary that the answer you will get, will be correct. So, instead, what you can do is, you can use this tool. This tool will write a code from behind the scenes, of factorial, and will give you the answer. Right? Next is Shell tool. You can run Shell commands, or you can run commands in the console. So, if you are making an application, where you, you know, you want to interact with the files of the system, on which the program is running, then you can use this tool there. Apart from that, there is a request get tool, with the help of which, you can make HTTP request. Gmail send message tool, with the help of which, you can email using Gmail. There is a different tool for Slack. There is a SQL database query tool, with the help of which, you can run SQL queries. So, you can see, the popular use cases, tools for them, have already been made and kept in the langchain. So, what I will do is, I will show you how to work with one or two tools. It is very simple. But, what will happen if you see once, that a little understanding will develop. So, what I will do is, I will take you to Google Colab, where I have already written this code. You just have to import some things, and, here is our first tool, which we are going to see. We will use DuckDuckGo Search. So, it may happen that, you are making such an agent application, where you need to search the web, in real time. Right? Suppose, your user comes, he asks you, tell me, what is the most important news of today? Right? So, LLM will not have this knowledge. Because, LLM has a knowledge cut-off date. So, with the help of this particular tool, what you can do is, you will quickly search DuckDuckGo, and from there, you will bring the search results and give it to LLM. And then, LLM will prepare an answer according to that result, and will give it to the user. So, first of all, what you have to do is, you have to import this tool from the langchain community.tools. DuckDuckGo Search Run. After that, you will make an object of this class, which we will call Search Tool. Now, what is the fun part? I haven't told you this yet. These tools are also runnable. Which means, they also have their own invoke function. So, what we are doing is, we are taking this tool, and calling the invoke function. And here, you can give any term. For now, I have put IPL News. Now, IPL is running. You can put anything here. Whatever term you put here, behind the scenes, that query will be picked up, on DuckDuckGo's search engine. There, the query will be searched. The results that will come, you will get them back. So, behind the scenes, all this is happening here. And then, what I am doing is, I am printing the result. So, if I run this code, then see this. Virat Kohli's all time reading run getter. Whatever it is. And, after this, further on, CSK IPL player qualification scenario is telling you, with 4 points from 8 matches. Whatever IPL you are following now, you will know that, this is your, IPL related news. Okay. According to this, you can search, Top News in India, today. So, here you will see, related news. Pahalgam, Kashmir, whatever bad incident happened just now, news is being shown here. Okay. So, you can see, how easy it is, how easy it is, for you, to perform this search. You can quickly, integrate this tool, with LLM. And, you can show your user, anything in real time, whatever is needed. Okay. So, this is the first tool, which I wanted to show you. And, this is very popular. Means, this will be seen in many use cases. Okay. After this, one more tool, which I want to show you, is the shell tool. So, I told you a little while ago, what is a shell tool? With the help of this, you can go to the command line, and execute commands. Whichever machine, this code is running. So, we again said, import the shell tool, from the landchain community, with the help of the tool. In the same way, we made the object again. And, this is also a runnable. So, I called invoke. And, here I passed this command, whoami. Which will tell, what is the name of my user, on the current machine. So, if I run this code, then, this is running on Google call app. Okay. There is some issue, with the import. So, I will pause the video, and, figure out, what is the name of the user. So, I will pause the video, and, try to figure out, the name of the user. So, yeah guys, this problem is solved. So, actually, you have to install, this dependency, landchain experimental. Without this, shell tool is not working. So, we have installed, that dependency. And, after that, when I run this code, whoami, then, see, the result is here. This current computer, on which our program is running, will be the server of Google call app. There, the name of our user is, root. Okay. And, here, you can also use, ls, to list, all the files, in the current directory. So, you can see, a sample data, folder is being displayed. Which is true, if you worked with Google call app, then you will know, that there, you get, a sample data, called folder. So here, you can run many commands, whatever, command line, you have learned. So, you can run, those commands. This tool, is useful, but, especially in production setup, be careful because you are executing command line arguments so some files can be deleted, so just be careful about this so in a nutshell I just wanted to show you how easy it is to use the built in tools of the land chain so these are two very basic tools but if you want to see the complete list of built in tools that I have available then you have to go to this link, here you will get the list of all the built in tools that exist in the land chain like there are many tools related to search, like bing, brave, dug dug go, google is also different then you have different tools to run your code, productivity related tools are github, jira, office, slack, twilio and so on there are different tools for web browsing, different tools for databases, finance and this is the complete list now the good thing is that you can go to any of these tools and for example we will go to this so here you will get the complete description and a working code what you can do is you can go through and learn to run that tool mostly things are very simple in fact, you can do this by going through the tools and learning to run them in fact, in some places you can not only work with that tool but at the same time you can also use it to build an agent so it is a very good documentation I would recommend you to go through the tools that you find interesting so now you have some idea about how to use built in tools in land chain now let's talk about what if you come across a use case where no built in tool exists related to it in that case you have to make your own tool and that is what we are going to learn next how to make custom tools in land chain now you have understood about custom tools that you have to make custom tools when you do not have any built in tool for your use case but I would like to give you a general outline that when does it happen that you have to make custom tools so these are some of the most popular use cases where you have to make custom tools first when you want to call your own API's in your application suppose you have a big application like make my trip where there is a lot of travel booking and hotel booking now for this you want to make an agent for your website where the user will not only talk to that agent but also book the booking so now what you need to do to make this agent work is that he can enter your database and perform the bookings so all this can be done through API's so somehow your agent will have to connect with your API's so to perform this work you have to make custom tools second use case is that you want to encapsulate your business logic which is again unique to your application so for that you will not get built in tool so you have to make custom tools for that and lastly if you want your LLM to interact with your own database, product or app so basically in a nutshell if you already have an application and you want to make an agent for that application then you have to make custom tools for that application so to interact with that agent with your existing application infrastructure you will have to make custom tools for that application and that can't be provided by a land chain so now I will show you a use case where we have an existing database and then we will create tools with which our agent can communicate with our database so let's do one thing first of all I will show you that how you can make your own tool in land chain we will take a very simple example but that will clear everything for you also there are multiple ways to make your own tool in land chain what I am going to tell you now is the simplest and straight forward way but going forward I will tell you more other ways so let's go back to the code now first of all what you have to do is from the land chain core.tool you have to import the tool now making a tool is a three step process first of all you have to make a function for your tool so let's assume we are taking a very simple use case let's assume our LLM doesn't know how to do multiplication because it doesn't know mathematics so what we are doing is we are building an external function which if you give two numbers then that function will return the product of those two numbers so what we did first is we made this function in step 1 a very simple python function just like we have made in the past but one thing you will notice differently that we have added a docstring in this function which is telling us what this function does now this docstring is not necessary in this function but it is highly recommended that you provide this docstring because with the help of this docstring in future our LLM will understand what this function or this tool does so it is highly recommended that you add this docstring so step 1 is done we have made this function step 2 you add type hinting in your function so if you want a and b in the input then you will tell what type of a and b is going to be there if your function returns an integer then you will tell that this function returns an integer we call this type hinting now this is not an important step either but it is highly recommended that you write in the function this way LLM understands what type of data it has to give in the input and what type of data it can expect by turning it over with this tool so in step 1 we made the function in step 2 we added type hinting now comes the final step where you put at the rate tool decorator on top of this function now what does at the rate tool decorator do it makes this function a special function and what can this special function do it can communicate with LLM or it can communicate with this function so all the magic is hidden in this decorator so going forward if you want to make any tool of your own then you have to do only 3 things first write the logic of that function second add type hinting and third add at the rate tool decorator on top of that and that's it by doing this much your tool will be made now the tool is made now I will show you how you can use this tool so you don't have to do anything you just need to call the name of this tool multiply and since this is a tool it means it is runnable so it has invoke function and what you will do in invoke function you will pass a dictionary where you will tell what is the value for every input so I am telling you pass this function in A as 3 and pass in B as 5 and I have run this code and now I am printing the result and you can see 15 so I know nothing special happened we are simply using a function but this function is not a normal function this is a tool and with this tool LLM can interact which I will show you in the next video when I will teach you the concept of tool calling but now we have just created our first tool now I will show you how this function is special this tool has some other capabilities like if you take the name of this tool and print the dot name then you will see the name of this tool similarly if you take this tool and print the dot description then you will get the description of this tool and if you take this tool and print the dot arguments then you will see all the arguments which are required to work on this tool so if I run this cell then see this is the name of our tool this is generally the name of the function after that what is the description of the tool? multiply two numbers this is exactly the thing which you provided in the doc string and lastly this is your arguments so here it is being told that there are two arguments A and B the first one is capital A and the second one is capital B and what is their type? integer and where did this come from? from this type hunting which we provided so so whenever you have any tool you will get these three attributes in fact these three attributes you will get here also see this if I show you the duck duck go one so what we have to do is we have to replace the multiply with search tool and since this is also a tool then it also has a name it also has a description and it also has a name of arguments see this this tool's name is duck duck go search this is the description a wrapper around duck duck go search useful when you need an answer question about current events input should be a search query and this is your arguments parameter ok I hope you are understanding things till here that any tool which you will see in the land chain associated with that tool you will get a name attribute description attribute arguments attribute ok? one more thing I want to show you that when you send this tool to LLM then what does LLM see? LLM does not see this tool LLM sees this if you run this piece of code then you will see a big JSON schema if I can show you by copying it in a better way copy we are going to a JSON formatter and we are going to paste it here and we are going to process it see this so when we connect our tool and LLM then LLM actually sees this thing rather than we send the logic of that function to LLM which is visible on your screen this is your tool's schema so whenever you connect tool and LLM then you do not send tool to LLM but you send the logic of the tool to LLM so in this you can see it is very readable description is written in properties A and B both are required title is multiply and type is object so in this way you can generate your built in tools and see what information is going to LLM about this tool so I hope you understood the basic idea how you can create custom tools using langchain now I will tell you some more methods with which you can create custom tools now guys you have seen one method of creating tools with the help of tool decorator apart from this there are two more methods actually there are more than two methods but there are two more methods which you will see commonly one is to create tools with the help of structured tool and pidentic and second is to create tools with the help of base tool class so these three methods you will see commonly apart from this there are other methods but they were used earlier so lets discuss the second method how you can create a custom tool with the help of structured tool class and pidentic so here I have written a definition of structured tool so a structured tool in langchain is a special type of tool the input to the tool follows a structured schema typically defined using a pidentic model so the basic thing is that the second method is a little more strict of creating tools till now we were creating tools with the help of tools there we were sending the inputs in our function we were just telling them with type hinting that this will be an integer and the output of the function will also be an integer but this is a very loose method ok what you can do is you can enforce these constraints using something like a pidentic model which we have studied in the past in this playlist so the basic thing is you will create the function in the same way but you will enforce the type of arguments with the help of pidentic model again something which you will understand better after seeing the code so here is the code so first of all you have to import the structured tool class from the langchain.tools second you have to import the base model and field from pidentic now what you will do like before you will create the function ok your function name is multiply function and you have defined a and b if you want you can not define type hint here because what you have done here you have made a pidentic class which is inheriting from the base model obviously and here I have told you that in this pidentic class there are two attributes a and b which are both integer and then I have added extra description about these two fields so both are required true means both should be there and I have given the description of both so I will add second so this is my pidentic model this is my function now here the main work starts now what we will do is call structured tool.from function and here we will tell things first of all we will tell what is our function with the help of which we have to make the tool after that we will give a name to that function we will also give a description here ok and this is the most important step in argument schema we will multiply in the function the input which is our pidentic class we will provide that ok so here you can see that you are not doing all the work in a function you are doing all the work here ok here you are telling which function to use to make the tool you are giving a name to that tool you are giving a description to that tool and you are enforcing your argument schema separately using a pidentic model so this is a little more mature way if you are ready for production and you want to make agents then this method will help you more but again in most of the cases the decorator method is used and it will work ok so let's do one thing we will make this once and run it and here everything will work in the same way you can invoke this too and around this you will get description name etc ok here also you can see some additional things required true ok and its own description all this is coming from our pidentic model ok so I hope you understood there is not much difference the only difference is that you are using this class to make your tool and separately you are providing an input schema which is enforcing constraints in a strict way that's it that's the only difference now let's talk about the third method so the third method is to make your custom tool with the help of base tool class now to understand this first you should know what is base tool class so here it is written base tool is the abstract base class for all tools in land chain it defines the core structure and interface that any tool must follow whether it is a simple one liner or a fully customized function all other tool types like at the rate tool or structured tool are built on top of base tool ok so the basic thing is there is an abstract class in land chain which is called base tool now when you make any tool whether it is a built in tool all these tools have to be inherited by base tool class because in base tool class it is told that a tool will behave in the land chain so the tool you made with the help of at the rate tool decorator or the tool I just showed you with the help of structured tool all these tools by default inherit base tool class so now what we will do rather than using these methods we will inherit base tool class and make our own tool so let me show you the code so for this you have to import base tool from landchain.tools and type from typing again I told you about typing I remember in some video I told you about typing so first of all you have to make a class which is called multiply tool and the special thing is this multiply tool class is inheriting base tool class means our class is the child of base tool class now what you can do here you can define your own attributes you can define your own functions so the first function is name no function I am sorry attribute is name where you name your tool second is description where you describe what your tool does after that here you can send your argument schema so what we have done here we have defined a separate argument schema using pydantic like we did in the above one see this is same thing so here we have made the same schema we have defined same schema here that our tool will get two things in input a and b both integers and description so now what I am doing here in my multiply tool class is this multiply input which I have defined above and type is this multiply input pydantic schema its type is base model basically it is a pydantic schema now here you define your most important run method under root run method its name should be exactly this you can't write anything else so here you have told that you will get a and b and that's it guys this class you have made is now inheriting base tool class and hence this class also becomes a tool in lang chain now you make its object like we have made object and once you have object then you will call dot invoke and pass input and you will get the answer and like earlier you can print name description and arguments in the same way this method gives you many benefits you can do many deep level customizations here in fact you can create an async version of your tool you don't get that feature in tool decorator and also not in structure tool but here you can create an async version of your tool if you are making any application where you have to handle concurrency then you will use this particular method but again in my experience to experiment at basic level at the rate tool decorator is sufficient and in 80-90% scenarios the first method with its help you will make tool and get your work done there will be certain scenarios where you are working on production ready application or production level application so there you will have the opportunity to use other methods that is why I have told you both again you can go to planchain documentation and explore things so in this video we have learned about tools we have learned about built in tools we have learnt how to make our own tools and we have seen 3 different ways to make our own tools now I want to cover one last topic and that is tool kits ok so what is the funda of tool kit so if you are making multiple tools for your application and those tools are related to each other so you can club those tools and form a tool kit ok like suppose you are making multiple tools related to google drive one is to upload files on google drive another is to search files on google drive another is to read files on google drive now all these tools are related to google drive so what you can do is by clubbing all these tools you can form a tool kit called google drive tool kit ok so this concept exists in langchain you will also get built in tool kits in langchain and if you want you can make your own custom tool kits see here let us read the definition a tool kit is just a collection of related tools that serve a common purpose packaged together for convenience and reusability so the biggest benefit of making tool kits is reusability you have made tool kit and kept it you can use it in one application or in any other application so that is the main funda behind creating tool kits ok so i will show you a custom tool kit with the help of langchain first of all what you have to do is you have to make 2 or more tools which are related like what we are doing we are making 2 tools one is to add and the other is to multiply and both these tools are related because both are doing arithmetic operations ok and to make these tools we are using tool decorator method you can use other method also now here the main work starts whatever tool kit you want to make you can make a custom tool kit you make a class for it so we made a class and the name of the class we kept the same name of the tool kit so our tool kit name is math tool kit now what you have to do is define a method by saying get tools and here what you will do is you will return the name of the tools which you want to be part of this tool kit so i have made add and multiply part of this tool kit now what you can do is you can easily make the object of your tool kit and when you will do toolkit.get tools then you will get all the tools which exist in your tool kit now what you can do is by running a loop you can access all these tools you can run them you can check their name, description, args so this is the main benefit of using tool kit that you can access all of them and also you have the point of view of reusability so this was a very small concept but i thought i should cover it so yeah that's it for the video guys i know you might be feeling incomplete that we have learnt how to make tools but we have not learnt how to connect with LLM the reason for that is we will cover this topic in next video when i will teach you tool calling so today's video's main point was to teach you about tools i really hope i could teach you everything is clear around tools now next video in fact next and next video both are very interesting because in next videos we will use these tools with LLMs so if you liked this video please like it and if you have not subscribed to this channel please do subscribe see you in next video bye